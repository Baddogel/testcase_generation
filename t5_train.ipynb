{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Cove\\Python Projects\\testcase_generation\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_linear_schedule_with_warmup, DataCollatorForSeq2Seq\n",
    "from datasets import load_from_disk\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF16 is supported! Using bfloat16 mixed precision\n"
     ]
    }
   ],
   "source": [
    "# Настройки\n",
    "MODEL_NAME = \"google/flan-t5-small\"\n",
    "MODEL_PATH = \"models/t5-testcase\"\n",
    "BATCH_SIZE = 16\n",
    "MAX_INPUT_LENGTH = 32\n",
    "MAX_TARGET_LENGTH = 80\n",
    "LEARNING_RATE = 3e-4\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Проверка поддержки bf16\n",
    "if DEVICE.type == \"cuda\" and torch.cuda.is_bf16_supported():\n",
    "    print(\"BF16 is supported! Using bfloat16 mixed precision\")\n",
    "else:\n",
    "    raise ValueError(\"BF16 is not supported on your device\")\n",
    "\n",
    "# Загрузка датасета\n",
    "dataset = load_from_disk(\"dataset\")\n",
    "train_dataset = dataset[\"train\"].select_columns([\"test_scenario\", \"test_steps\"])\n",
    "test_dataset = dataset[\"test\"].select_columns([\"test_scenario\", \"test_steps\"])\n",
    "\n",
    "# Загрузка токенизатора\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Загрузка модели\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенизированные длины для test_scenario:\n",
      "{'max': 32, 'min': 4, 'avg': 16.223233995584987, 'p95': 23}\n",
      "\n",
      "Токенизированные длины для test_steps:\n",
      "{'max': 80, 'min': 9, 'avg': 36.45115894039735, 'p95': 56}\n"
     ]
    }
   ],
   "source": [
    "# Функция для анализа длин в токенах\n",
    "def analyze_token_lengths(dataset, column_name):\n",
    "    token_lengths = [len(tokenizer.encode(text)) for text in dataset[column_name]]\n",
    "    max_length = max(token_lengths)\n",
    "    min_length = min(token_lengths)\n",
    "    avg_length = sum(token_lengths) / len(token_lengths)\n",
    "    p95_length = sorted(token_lengths)[int(len(token_lengths) * 0.95)]\n",
    "    return {\n",
    "        \"max\": max_length,\n",
    "        \"min\": min_length,\n",
    "        \"avg\": avg_length,\n",
    "        \"p95\": p95_length\n",
    "    }\n",
    "\n",
    "# Анализ длин входных данных в токенах\n",
    "input_token_stats = analyze_token_lengths(train_dataset, \"test_scenario\")\n",
    "print(\"Токенизированные длины для test_scenario:\")\n",
    "print(input_token_stats)\n",
    "\n",
    "# Анализ длин выходных данных в токенах\n",
    "target_token_stats = analyze_token_lengths(train_dataset, \"test_steps\")\n",
    "print(\"\\nТокенизированные длины для test_steps:\")\n",
    "print(target_token_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Токенизация данных\n",
    "def preprocess_function(examples):\n",
    "    inputs = [f\"generate test steps: {scenario}\" for scenario in examples[\"test_scenario\"]]\n",
    "    targets = examples[\"test_steps\"]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_tokenized = train_dataset.map(preprocess_function, batched=True)\n",
    "test_tokenized = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Добавляем форматирование в тензоры\n",
    "train_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Используем специальный коллектор для seq2seq\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Создание DataLoader\n",
    "train_dataloader = DataLoader(train_tokenized, shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(test_tokenized, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "\n",
    "\n",
    "\n",
    "# Оптимизатор и scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   5%|▍         | 218/4540 [00:29<09:39,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   5%|▌         | 227/4540 [00:22<07:27,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   5%|▌         | 228/4540 [00:24<42:11,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5956\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  10%|▉         | 453/4540 [00:46<06:40, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  10%|█         | 455/4540 [00:48<28:43,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5465\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  15%|█▍        | 680/4540 [01:11<06:44,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  15%|█▌        | 682/4540 [01:13<33:02,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5099\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  20%|██        | 908/4540 [01:35<05:57, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5469\n",
      "Validation Loss: 0.4833\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  25%|██▌       | 1135/4540 [01:59<05:52,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  25%|██▌       | 1136/4540 [02:01<34:30,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4591\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  30%|███       | 1362/4540 [02:23<05:37,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  30%|███       | 1363/4540 [02:25<34:01,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4431\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  35%|███▍      | 1588/4540 [02:48<04:35, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  35%|███▌      | 1590/4540 [02:50<18:05,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4251\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  40%|████      | 1816/4540 [03:12<04:11, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4173\n",
      "Validation Loss: 0.4100\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  45%|████▌     | 2043/4540 [03:36<03:48, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  45%|████▌     | 2045/4540 [03:38<15:10,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3993\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  50%|█████     | 2270/4540 [04:00<03:31, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3744\n",
      "Validation Loss: 0.3915\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  55%|█████▌    | 2497/4540 [04:24<03:07, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3560\n",
      "Validation Loss: 0.3789\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  60%|██████    | 2724/4540 [04:48<02:43, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3402\n",
      "Validation Loss: 0.3747\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  65%|██████▌   | 2951/4540 [05:13<02:27, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3257\n",
      "Validation Loss: 0.3675\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  70%|██████▉   | 3177/4540 [05:37<02:09, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  70%|███████   | 3179/4540 [05:39<08:49,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3643\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  75%|███████▍  | 3404/4540 [06:01<01:59,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  75%|███████▌  | 3406/4540 [06:03<09:08,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3592\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  80%|████████  | 3632/4540 [06:25<01:31,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  80%|████████  | 3633/4540 [06:27<07:31,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3548\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  85%|████████▍ | 3858/4540 [06:49<01:10,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  85%|████████▌ | 3860/4540 [06:51<05:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3527\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  90%|█████████ | 4086/4540 [07:13<00:45,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  90%|█████████ | 4087/4540 [07:15<04:09,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3519\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  95%|█████████▍| 4312/4540 [07:37<00:23,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  95%|█████████▌| 4314/4540 [07:39<01:39,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3514\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|█████████▉| 4539/4540 [08:01<00:00,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2785\n",
      "Validation Loss: 0.3514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/t5-testcase\\\\tokenizer_config.json',\n",
       " 'models/t5-testcase\\\\special_tokens_map.json',\n",
       " 'models/t5-testcase\\\\spiece.model',\n",
       " 'models/t5-testcase\\\\added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение с прогресс-баром\n",
    "progress_bar = tqdm(range(total_steps), desc=\"Training progress\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        \n",
    "        with torch.autocast(device_type=DEVICE.type, dtype=torch.bfloat16, enabled=True):\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Валидация после эпохи\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_dataloader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    model.train()\n",
    "\n",
    "# Сохранение модели\n",
    "model.save_pretrained(MODEL_PATH)\n",
    "tokenizer.save_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка дообученной модели\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=MODEL_PATH,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "# Загрузка токенизатора\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Перемещение модели на GPU или CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вход: Verify that a user cannot download content that does not support offline viewing.\n",
      "Ожидаемый результат: 1. Navigate to content that does not have offline viewing support.\n",
      "2. Check for the download button.\n",
      "Сгенерированный результат: 1. Log in to the streaming platform. 2. Navigate to a content that does not support offline viewing. 3. Attempt to download the content.\n"
     ]
    }
   ],
   "source": [
    "# Проверка генерации\n",
    "model.eval()\n",
    "generation_config = {\n",
    "    \"max_length\": MAX_TARGET_LENGTH,\n",
    "    \"num_beams\": 4,\n",
    "    \"early_stopping\": True,\n",
    "    \"no_repeat_ngram_size\": 2,  # Запрет повторяющихся биграмм\n",
    "    \"temperature\": 0.7,         # Добавление случайности\n",
    "    \"top_k\": 50,                # Ограничение топ-k токенов\n",
    "    \"top_p\": 0.95,              # Ядерная выборка\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "def generate_test_steps(scenario):\n",
    "    inputs = tokenizer(f\"generate test steps: {scenario}\", return_tensors=\"pt\").to(DEVICE)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        **generation_config\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Пример генерации на тестовых данных\n",
    "sample = test_dataset.shuffle().select([0])[0]\n",
    "print(\"Вход:\", sample[\"test_scenario\"])\n",
    "print(\"Ожидаемый результат:\", sample[\"test_steps\"])\n",
    "print(\"Сгенерированный результат:\", generate_test_steps(sample[\"test_scenario\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
